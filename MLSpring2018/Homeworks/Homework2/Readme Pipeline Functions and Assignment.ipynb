{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component in the pipeline library is the import of all \n",
    "relevant packages to make the pipeline work. These packages are\n",
    "found in the first cell and can be modified as desired, according\n",
    "to the needs of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has the simplest function to open and read a csv file.\n",
    "This function has to be modified when there are different delimiters\n",
    "or headers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has different functions to explore the data. These create:\n",
    "    - Scatterplots\n",
    "    - Histograms\n",
    "    - A correlation dataframe between a variable of interest and the rest\n",
    "    of variables in the dataframe\n",
    "    -A function to count nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pre-Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has functions to:\n",
    "    - Impute data using KNN\n",
    "    - Impute data setting values to mean\n",
    "    - Recode Outliers\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate and select Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has functions to:\n",
    "    - Create bins using quantiles or defining buckets by hand\n",
    "    - Create dummy variables\n",
    "    - Select the best features using randomforests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate and Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline evaluate the accuracy of different models using a nested loop for different parameters. Then it conducts a confusion matrix analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, I followed the steps and code in https://github.com/yhat/DataGotham2013/\n",
    "Using some of the functions in the repo above, and some others created on my own, I made a function to read the data and create a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I made some initial data exploration using histograms and scatterplots, as well as descriptive statistics using all the data.\n",
    "To process the data, first I partitioned my data into train and test. Then I imputed the missing values of the variable 'Monthly Income', assigning the value of the mean monthly income. I did this operation for each dataset (for test and train).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the features for the models, first I discretized the variables for income, age and debt ratio, creating bins. Then I assigned a dummy variable for each bin in which each of these variables was partioned into.\n",
    "The debt ratio variable was partioned into quartiles (25%).  I set the outliers of the income variable equal to the median and then partioned into quintiles (20%). Finally, I used age buckets following DataGotham. For each of these discrete categories, a dummy variable was created, with the aim of capturing non-linear effects of these features on the label.\n",
    "For the sake of constructing the ML pipeline, I also ran a randomforest analysis, in order to capture which variables are the best predictors. At the end, however, while building the classifier I included all variables except the continous ones for income, age and debt ratio, and one of the dummy categories for the bins of said features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the model with the highest accuracy rate, I run several models with different parameters using a nested loop. Once I obtained a model with the highest rate of accuracy in the test data, I proceeded to construct a confusion matrix.\n",
    "The selected model showed an accuracy of 87% (which may suggest an overfit), and when I ran the confusion matrix, it showed that the model classifies true positives with an average rate of 86%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
